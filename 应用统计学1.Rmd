---
title: "应用统计学1"
output: html_document
date: "2022-09-14"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# question 1 Introduce the distributions with an example

## define function to analysis the sample data

#### I find some example data about the distributions, and make some code (include calculating var and expect value and draw the plot of mass function and CPF) to analysis it.

```{r}
setwd("C:/Users/20530/Desktop/")
getwd()

myfun <- function(name){#用于测试数据的函数
  #读取
  data <- read.table(name,sep = '\n',header = TRUE)
  value = ts(data)
  plot(value,xlab = name,ylab = "value")
  #方差
  varvalue = var(value)
  print(paste('varvalue =',as.character(varvalue[1,1])))
  expectvalue = mean(value)#均值
  print(paste('expectvalue =',as.character(expectvalue)))
  #密度函数
  density(value)
  plot(density(value),xlab = name)
  #概率
  court = table(value)
  prob = court/100
  plot(prob,xlab = name)
  #累计概率
  x <- seq(0.1, 50, by=0.1)
  if(name=='exp.txt'){
    plot(x, pexp(x, 1), type="l",xlab = name,ylab ="cum")
    #browser()
  }
  else if(name=='gamma.txt'){
    plot(x, pexp(x, 1), type="l",xlab = name,ylab ="cum")
  }else{
    cum <- cumsum(prob)
    plot(cum,xlab = name,ylab ="cum")
  }
  #browser()
  return(0)
}
first = c('binom','pois','exp','gamma','hyper')
second = 'txt'

```

## Binomial Distribution

#### In probability theory and statistics, the binomial distribution with parameters n and p is the discrete probability distribution of the number of successes in a sequence of n independent experiments, each asking a yes–no question, and each with its own Boolean-valued outcome: success (with probability p) or failure (with probability q = 1 − p). A single success/failure experiment is also called a Bernoulli trial or Bernoulli experiment, and a sequence of outcomes is called a Bernoulli process; for a single trial, i.e., n = 1, the binomial distribution is a Bernoulli distribution. The binomial distribution is the basis for the popular binomial test of statistical significance.

### Probability mass function:

![Probability mass function](C:/Users/20530/Desktop/binommass.svg "Probability mass function")

### Cumulative distribution function:


![Cumulative distribution function](C:/Users/20530/Desktop/binomcum.svg "Cumulative distribution function")


```{r}
for (f in first) {
  #分析指定样本
  if(f=='binom'){
    name = paste(f,second,sep = '.')
    a = myfun(name = name)
  }
}
```


## Poisson Distribution

#### In probability theory and statistics, the Poisson distribution is a discrete probability distribution that expresses the probability of a given number of events occurring in a fixed interval of time or space if these events occur with a known constant mean rate and independently of the time since the last event.[1] It is named after French mathematician Siméon Denis Poisson (/ˈpwɑːsɒn/; French pronunciation: ​[pwasɔ̃]). The Poisson distribution can also be used for the number of events in other specified interval types such as distance, area or volume.

### Probability mass function:

![Probability mass function](C:/Users/20530/Desktop/poismass.svg "Probability mass function")

```{r}
for (f in first) {
  #分析指定样本
  if(f=='pois'){
    name = paste(f,second,sep = '.')
    a = myfun(name = name)
  }
}
```

##  Hypergeometric distribution

#### In probability theory and statistics, the hypergeometric distribution is a discrete probability distribution that describes the probability of {\displaystyle k}k successes (random draws for which the object drawn has a specified feature) in {\displaystyle n}n draws, without replacement, from a finite population of size {\displaystyle N}N that contains exactly {\displaystyle K}K objects with that feature, wherein each draw is either a success or a failure. In contrast, the binomial distribution describes the probability of {\displaystyle k}k successes in {\displaystyle n}n draws with replacement.

### Probability mass function:

![Probability mass function](C:/Users/20530/Desktop/hypermass.svg "Probability mass function")

### Combinatorial identities :


![Combinatorial identities](C:/Users/20530/Desktop/hypercom.svg "Combinatorial identities")

```{r}
for (f in first) {
  #分析指定样本
  if(f=='hyper'){
    name = paste(f,second,sep = '.')
    a = myfun(name = name)
  }
}
```

## Exponential distribution

#### In probability theory and statistics, the exponential distribution is the probability distribution of the time between events in a Poisson point process, i.e., a process in which events occur continuously and independently at a constant average rate. It is a particular case of the gamma distribution. It is the continuous analogue of the geometric distribution, and it has the key property of being memoryless. In addition to being used for the analysis of Poisson point processes it is found in various other contexts.

### Probability mass function:

![Probability mass function](C:/Users/20530/Desktop/expmass.svg "Probability mass function")

### Cumulative distribution function:


![Cumulative distribution function](C:/Users/20530/Desktop/expcum.svg "Cumulative distribution function")

```{r}
for (f in first) {
  #分析指定样本
  if(f=='exp'){
    name = paste(f,second,sep = '.')
    a = myfun(name = name)
  }
}
```


## Gamma distribution

####In probability theory and statistics, the gamma distribution is a two-parameter family of continuous probability distributions. The exponential distribution, Erlang distribution, and chi-square distribution are special cases of the gamma distribution. 

### Probability mass function:

![Probability mass function](C:/Users/20530/Desktop/gammamass.svg "Probability mass function")


### Cumulative distribution function:


![Cumulative distribution function](C:/Users/20530/Desktop/gammacum.svg "Cumulative distribution function")


```{r}
for (f in first) {
  #分析指定样本
  if(f=='gamma'){
    name = paste(f,second,sep = '.')
    a = myfun(name = name)
  }
}
```